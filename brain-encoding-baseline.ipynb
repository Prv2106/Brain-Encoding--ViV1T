{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12497168,"sourceType":"datasetVersion","datasetId":7886942}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset\n\nclass MouseDataset(Dataset):\n    def __init__(self, root_dir):\n        self.videos_dir = os.path.join(root_dir, 'videos')\n        self.pupil_dir = os.path.join(root_dir, 'pupil_center')\n        self.behavior_dir = os.path.join(root_dir, 'behavior')\n        self.labels_dir = os.path.join(root_dir, 'labels')\n\n        self.file_ids = sorted(\n            [f.replace('.npy', '') for f in os.listdir(self.videos_dir) if f.endswith('.npy')],\n            key=lambda x: int(x)\n        )\n\n    def __len__(self):\n        return len(self.file_ids)\n\n    def __getitem__(self, i):\n        file_id = self.file_ids[i]\n\n        video = np.load(os.path.join(self.videos_dir, f'{file_id}.npy'))\n        pupil = np.load(os.path.join(self.pupil_dir, f'{file_id}.npy'))\n        behavior = np.load(os.path.join(self.behavior_dir, f'{file_id}.npy'))\n        label = np.load(os.path.join(self.labels_dir, f'{file_id}.npy'))\n\n        video = video[np.newaxis, ...]\n        \n        return {\n            'video': torch.from_numpy(video).float(),\n            'pupil_center': torch.from_numpy(pupil).float().transpose(1,0),\n            'behavior': torch.from_numpy(behavior).float().transpose(1,0),\n            'labels': torch.from_numpy(label).float()\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T10:32:15.686074Z","iopub.execute_input":"2025-07-17T10:32:15.686446Z","iopub.status.idle":"2025-07-17T10:32:15.696000Z","shell.execute_reply.started":"2025-07-17T10:32:15.686418Z","shell.execute_reply":"2025-07-17T10:32:15.694767Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"train_set = MouseDataset('/kaggle/input/mousedataset/train/data')\nvalidation_set = MouseDataset('/kaggle/input/mousedataset/validation/data')\ntest_set = MouseDataset('/kaggle/input/mousedataset/test/data')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T10:32:18.648454Z","iopub.execute_input":"2025-07-17T10:32:18.648772Z","iopub.status.idle":"2025-07-17T10:32:18.692128Z","shell.execute_reply.started":"2025-07-17T10:32:18.648747Z","shell.execute_reply":"2025-07-17T10:32:18.691312Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"train_set[0]['labels'].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T10:32:19.268365Z","iopub.execute_input":"2025-07-17T10:32:19.268680Z","iopub.status.idle":"2025-07-17T10:32:19.319492Z","shell.execute_reply.started":"2025-07-17T10:32:19.268656Z","shell.execute_reply":"2025-07-17T10:32:19.318460Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"torch.Size([227, 140])"},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"# BASELINE","metadata":{}},{"cell_type":"markdown","source":"N.B: TRAIN_SET\n* 0-41: indici associati a clip del natural_movie_one -> ogni 6 abbiamo una trial\n* 42-216: indici associati a clip del natural_movie_three -> ogni 25, una trial","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport statistics\n\n# funzione che prende in input train_set e restituisce la media dei dff di tutti i trial relativi ad una clip\ndef retrieve_dff_mean_among_trials_for_a_clip(movie_type: str , train_set: MouseDataset, clip: int):\n    \"\"\"\n    movie_type:\n        - \"one\"\n        - \"three\"\n\n    clip:\n        - \"one\": da 1 a 6 (file da 0.npy a 5.npy), ritorno con clip=2: [1.npy, 7.npy, 13.npy, ... , 37.npy]\n        - \"three\": da 1 a 25 (file da 42.npy a 66.npy), ritorno con clip=2: [43.npy, 68.npy, ... , 212.npy]\n    \n    \"\"\"\n    \n    offset = 6 if movie_type==\"one\" else 25\n\n    # Verifica che vengano passati parametri coerenti con il movie_type\n    if movie_type == \"one\":\n        # indici da 0 a 41 \n        assert 1 <= clip <= 6, f\"Per movie_type='one', clip deve essere tra 1 e 6, ricevuto: {clip}\"\n    elif movie_type == \"three\":\n        # indici da 42 a 216 \n        assert 1 <= clip <= 25, f\"Per movie_type='three', clip deve essere tra 1 e 25, ricevuto: {clip}\"\n    else:\n        raise ValueError(f\"movie_type deve essere 'one' o 'three', ricevuto: {movie_type}\")\n    \n    trials = []\n    start_idx = clip-1 if movie_type == \"one\" else clip+41\n    for i in range(7):\n        trials.append(train_set[start_idx]['labels'].numpy())\n        start_idx += offset\n    \n    # Media across trials: (7, 227, 140) → (227, 140)\n    mean_across_trials = np.mean(trials, axis=0)\n    return mean_across_trials","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T10:32:23.310204Z","iopub.execute_input":"2025-07-17T10:32:23.310491Z","iopub.status.idle":"2025-07-17T10:32:23.318420Z","shell.execute_reply.started":"2025-07-17T10:32:23.310472Z","shell.execute_reply":"2025-07-17T10:32:23.317054Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"PASSIAMO AL TEST","metadata":{}},{"cell_type":"code","source":"print(len(test_set)) # 62 -> 12 per \"one\" (prime 6 per trial 8) e 50 per \"three\" (prime 25 per trial 8)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T10:32:23.616162Z","iopub.execute_input":"2025-07-17T10:32:23.616606Z","iopub.status.idle":"2025-07-17T10:32:23.622014Z","shell.execute_reply.started":"2025-07-17T10:32:23.616580Z","shell.execute_reply":"2025-07-17T10:32:23.621008Z"}},"outputs":[{"name":"stdout","text":"62\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# ci recuperiamo i trial 8 e 9 del test per quanto riguarda clip 1 movie one\n# N.B: una volta confrontiamo con 8 e un'altra con la 9\nclip_1_type_one_test_trial8 = test_set[0]['labels'] \nclip_1_type_one_test_trial9 = test_set[6]['labels'] ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T10:32:23.757751Z","iopub.execute_input":"2025-07-17T10:32:23.758032Z","iopub.status.idle":"2025-07-17T10:32:23.839709Z","shell.execute_reply.started":"2025-07-17T10:32:23.758011Z","shell.execute_reply":"2025-07-17T10:32:23.838785Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"# ci recuperiamo i trial 8 e 9 del test per quanto riguarda clip 1 movie one\n# N.B: una volta confrontiamo con 8 e un'altra con la 9\nclip_1_type_three_test_trial8 = test_set[13]['labels'] \nclip_1_type_three_test_trial9 = test_set[38]['labels'] ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T10:32:23.882861Z","iopub.execute_input":"2025-07-17T10:32:23.883155Z","iopub.status.idle":"2025-07-17T10:32:23.972548Z","shell.execute_reply.started":"2025-07-17T10:32:23.883133Z","shell.execute_reply":"2025-07-17T10:32:23.971640Z"}},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":"CORRELAZIONE","metadata":{}},{"cell_type":"code","source":"# Prima cella: calcolo della pearson correlation tra clip_1_type_one_train e test trials\nimport numpy as np\n\n# Poi correlazione neurone-per-neurone\ndef compute_neuron_correlations(mean_training, test_trial):\n    \"\"\"Calcola correlazione neurone-per-neurone\"\"\"\n    correlations = []\n\n    print(mean_training.shape)\n    for neuron in range(mean_training.shape[0]):\n        # Ogni neurone ha 140 time points\n        train_neuron = mean_training[neuron, :]  # shape (140,)\n        test_neuron = test_trial[neuron, :]      # shape (140,)\n        \n        # Controlla varianza\n        if np.var(train_neuron) > 1e-10 and np.var(test_neuron) > 1e-10:\n            corr = np.corrcoef(train_neuron, test_neuron)[0, 1]\n            if not np.isnan(corr) and np.isfinite(corr):\n                correlations.append(corr)\n    \n    return {\n        'mean_correlation': np.mean(correlations) if correlations else 0.0,\n        'valid_neurons': len(correlations),\n        'total_neurons': mean_training.shape[0]\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T10:32:25.530455Z","iopub.execute_input":"2025-07-17T10:32:25.530794Z","iopub.status.idle":"2025-07-17T10:32:25.538322Z","shell.execute_reply.started":"2025-07-17T10:32:25.530769Z","shell.execute_reply":"2025-07-17T10:32:25.537059Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"def pearson_correlation(predictions, labels):\n             \n    # Allineamento temporale per evaluation\n    min_frames = 66\n    labels_aligned = labels[..., -min_frames:]\n    predictions_aligned = predictions[..., -min_frames:]\n    \n    # Reshape per correlazione: da (batch, neurons, time) a (batch*time, neurons)\n    y_true = labels_aligned.transpose(1, 0)\n    y_pred = predictions_aligned.transpose(1,0)\n        \n    correlations = []\n        \n    for neuron in range(y_true.shape[1]): \n        # per ogni neurone, recuperiamo predizione e label\n        true_vals = y_true[:, neuron]\n        pred_vals = y_pred[:, neuron]\n        \n        # Controlla varianza\n        true_var = np.var(true_vals)\n        pred_var = np.var(pred_vals)\n        \n        \"\"\"\n        filtriamo neuroni con attività praticamente costante (varianza quasi zero) prima di calcolare la correlazione. \n        Questo evita divisioni per zero nella formula della correlazione di Pearson.\n        Neuroni \"morti\" o inattivi, comuni nei dataset neurali, avrebbero correlazioni matematicamente indefinite, \n        quindi vengono esclusi dal calcolo delle metriche. Solo neuroni con variabilità significativa \n        sia nei dati reali che nelle predizioni contribuiscono alla metrica finale di correlazione media, \n        garantendo risultati statisticamente validi.\n        \"\"\"\n        if true_var > 1e-10 and pred_var > 1e-10:\n            corr = np.corrcoef(true_vals, pred_vals)[0, 1]\n            if not np.isnan(corr) and np.isfinite(corr):\n                correlations.append(corr)\n    \n    mean_correlation = np.mean(correlations) if correlations else 0.0\n        \n    return {\n        'eval_single_trial_correlation': mean_correlation,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T10:32:27.038033Z","iopub.execute_input":"2025-07-17T10:32:27.038369Z","iopub.status.idle":"2025-07-17T10:32:27.046466Z","shell.execute_reply.started":"2025-07-17T10:32:27.038344Z","shell.execute_reply":"2025-07-17T10:32:27.045175Z"}},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":"## APPROCCIO A \"CAMPIONE\"","metadata":{}},{"cell_type":"markdown","source":"Per il calcolo della baseline abbiamo proceduto nel modo seguente:\nIl nostro train_set prevede 7 trials (da 0 a 7) sia di “natural_movie_one” che di “natural_movie_three” e per il processamento che abbiamo fatto relativamente al dataset (segmentazione) abbiamo ottenuto che il video di tipo “one”  consiste in 6 clip, mentre quello di tipo “three” in 25. Ciascuna clip ha shape (227,140).","metadata":{}},{"cell_type":"code","source":"# calcolo della pearson correlation tra clip_1_type_one_train e clip_1_type_one_test_trial8\nclip_1_type_one_train = retrieve_dff_mean_among_trials_for_a_clip(\"one\", train_set, 1)\nresult = pearson_correlation(clip_1_type_one_train, clip_1_type_one_test_trial8.numpy())\nprint(result) # 0.16688079896142594","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T10:32:29.640128Z","iopub.execute_input":"2025-07-17T10:32:29.640445Z","iopub.status.idle":"2025-07-17T10:32:29.907169Z","shell.execute_reply.started":"2025-07-17T10:32:29.640422Z","shell.execute_reply":"2025-07-17T10:32:29.906169Z"}},"outputs":[{"name":"stdout","text":"{'eval_single_trial_correlation': 0.1668819363680424}\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# calcolo della pearson correlation clip_1_type_one_train con clip_1_type_one_test_trial9\nresult = pearson_correlation(clip_1_type_one_train, clip_1_type_one_test_trial9.numpy())\nprint(result) # 0.15149332381948732","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T10:32:31.320819Z","iopub.execute_input":"2025-07-17T10:32:31.321161Z","iopub.status.idle":"2025-07-17T10:32:31.364052Z","shell.execute_reply.started":"2025-07-17T10:32:31.321132Z","shell.execute_reply":"2025-07-17T10:32:31.363293Z"}},"outputs":[{"name":"stdout","text":"{'eval_single_trial_correlation': 0.15162855863439018}\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# calcolo della pearson correlation clip_1_type_three_train con clip_1_type_one_test_trial8\nclip_1_type_three_train = retrieve_dff_mean_among_trials_for_a_clip(\"three\", train_set, 1)\nresult = pearson_correlation(clip_1_type_three_train, clip_1_type_three_test_trial8.numpy())\nprint(result) # 0.01626231821295263","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T10:32:31.728022Z","iopub.execute_input":"2025-07-17T10:32:31.728352Z","iopub.status.idle":"2025-07-17T10:32:32.007581Z","shell.execute_reply.started":"2025-07-17T10:32:31.728328Z","shell.execute_reply":"2025-07-17T10:32:32.006720Z"}},"outputs":[{"name":"stdout","text":"{'eval_single_trial_correlation': 0.016630593171042804}\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"pearson_correlation# calcolo della pearson correlation clip_1_type_three_train con clip_1_type_one_test_trial9\nresult = pearson_correlation(clip_1_type_three_train, clip_1_type_three_test_trial9.numpy())\nprint(result) # 0.025573463105490166","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T10:32:32.645384Z","iopub.execute_input":"2025-07-17T10:32:32.645714Z","iopub.status.idle":"2025-07-17T10:32:32.688502Z","shell.execute_reply.started":"2025-07-17T10:32:32.645692Z","shell.execute_reply":"2025-07-17T10:32:32.687604Z"}},"outputs":[{"name":"stdout","text":"{'eval_single_trial_correlation': 0.025459941873139214}\n","output_type":"stream"}],"execution_count":33},{"cell_type":"markdown","source":"Dunque, abbiamo recuperato le trial della stessa clip nel test_set (nello specifico, le trial 8 e 9) e, infine, abbiamo calcolato la pearson correlation tra l’array NumPy ottenuto prima (valore medio, per ciascun neurone, della sua intensità nelle 7 trial, frame per frame, relativamente ad una clip selezionata) e la clip del trial 8 prima, e con la clip del trial 9 poi. ","metadata":{}},{"cell_type":"markdown","source":"## APPROCCIO CON MEDIA DELLE CORRELAZIONI SINGLE TRIAL","metadata":{}},{"cell_type":"markdown","source":"Dopo averci ragionato su, abbiamo ritenuto che calcolare la baseline rispetto a tutte le clip del dataset fosse un approccio più corretto sia perchè riesce a dare informazioni più significative rispetto all’approccio a campione, sia perchè l’addestramento del modello segue questa metrica (infatti, il metodo compute_metrics che viene richiamato dal Trainer di HuggingFace lo abbiamo implementato proprio per far restituire la media delle single trial correlation su tutti i campioni del test_set ). \nConseguentemente, andando a fare l’evaluate() del modello sul test_set  si ottiene un valore che può essere confrontato direttamente con tale baseline. Nello specifico, abbiamo dapprima calcolato la correlazione tra le risposte del train_set e le clip del test_set relative alla trial 8 e poi abbiamo calcolato la correlazione tra le risposte del train_set e le clip del test_set relative alla trial 9. \n","metadata":{}},{"cell_type":"code","source":"list_array_numpy = [] # avrà len=31\nfor movie_type in [\"one\",\"three\"]:\n    _range = 6 if movie_type == \"one\" else 25\n    for i in range(_range):\n        list_array_numpy.append(retrieve_dff_mean_among_trials_for_a_clip(movie_type, train_set, i+1))\n\nprint(list_array_numpy[0].shape)\n# Convertiamo otteniamo un array 3D a partire dalla lista di array 2D\narray_3d_train = np.stack(list_array_numpy, axis=0)\nprint(array_3d_train.shape)  # (31, 227, 140)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T10:32:35.048410Z","iopub.execute_input":"2025-07-17T10:32:35.048717Z","iopub.status.idle":"2025-07-17T10:32:41.191946Z","shell.execute_reply.started":"2025-07-17T10:32:35.048695Z","shell.execute_reply":"2025-07-17T10:32:41.190960Z"}},"outputs":[{"name":"stdout","text":"(227, 140)\n(31, 227, 140)\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"# splittiamo i test set in 2 (trial 8 e 9):\n# - 31 clip in toale: le prime 6 per \"movie one\" e le altre 25 (successive) per \"movie three\" <-> trial 8\n# ...\n\ntrial_8_list = []\ntrial_9_list = []\nfor i in range(len(test_set)):\n    if i < 31:\n        trial_8_list.append(test_set[i]['labels'].numpy())\n    else:\n        trial_9_list.append(test_set[i]['labels'].numpy())\n\narray_3d_trial8_test = np.stack(trial_8_list, axis=0)\narray_3d_trial9_test = np.stack(trial_9_list, axis=0)\nprint(array_3d_trial8_test.shape)  # (31, 227, 140)\nprint(array_3d_trial9_test.shape)  # (31, 227, 140)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T10:32:41.193503Z","iopub.execute_input":"2025-07-17T10:32:41.193804Z","iopub.status.idle":"2025-07-17T10:32:42.843888Z","shell.execute_reply.started":"2025-07-17T10:32:41.193782Z","shell.execute_reply":"2025-07-17T10:32:42.843044Z"}},"outputs":[{"name":"stdout","text":"(31, 227, 140)\n(31, 227, 140)\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"def compute_metrics(predictions, labels):  \n    # Allineamento temporale\n    min_frames = 66\n    labels_aligned = labels[..., -min_frames:]\n    predictions_aligned = predictions[..., -min_frames:]\n    \n    # Lista per memorizzare correlazioni per ogni esempio\n    example_correlations = [] \n    \n    # Loop per ogni esempio nel batch\n    for example_idx in range(labels_aligned.shape[0]):\n        # Dati per questo esempio specifico\n        y_true_example = labels_aligned[example_idx].T  # (time, neurons)\n        y_pred_example = predictions_aligned[example_idx].T  # (time, neurons)\n        \n        correlations = [] \n        \n\n        for neuron in range(y_true_example.shape[1]):\n            true_vals = y_true_example[:, neuron]\n            pred_vals = y_pred_example[:, neuron]\n            \n            # Stesso filtering che avevi prima\n            true_var = np.var(true_vals)\n            pred_var = np.var(pred_vals)\n            \n            if true_var > 1e-10 and pred_var > 1e-10:\n                corr = np.corrcoef(true_vals, pred_vals)[0, 1]\n                if not np.isnan(corr) and np.isfinite(corr):\n                    correlations.append(corr)\n        \n        # Correlazione media per questo esempio\n        mean_corr_example = np.mean(correlations) if correlations else 0.0\n        example_correlations.append(mean_corr_example) \n    \n    # Statistiche aggregate\n    overall_mean = np.mean(example_correlations) if example_correlations else 0.0\n    \n    return {\n        'eval_average_single_trial_correlation': overall_mean,\n        'eval_single_trial_std': np.std(example_correlations) if example_correlations else 0.0,\n        'eval_num_examples': len(example_correlations),\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T10:32:42.844722Z","iopub.execute_input":"2025-07-17T10:32:42.845006Z","iopub.status.idle":"2025-07-17T10:32:42.852958Z","shell.execute_reply.started":"2025-07-17T10:32:42.844980Z","shell.execute_reply":"2025-07-17T10:32:42.852150Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"import statistics\n\nresults = [\n    compute_metrics(array_3d_train, array_3d_trial8_test)[\"eval_average_single_trial_correlation\"],\n    compute_metrics(array_3d_train, array_3d_trial9_test)[\"eval_average_single_trial_correlation\"]\n]\nprint(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T10:32:42.854834Z","iopub.execute_input":"2025-07-17T10:32:42.855508Z","iopub.status.idle":"2025-07-17T10:32:44.863665Z","shell.execute_reply.started":"2025-07-17T10:32:42.855486Z","shell.execute_reply":"2025-07-17T10:32:44.862569Z"}},"outputs":[{"name":"stdout","text":"[0.007424696253855147, 0.03706561983790726]\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"print(f\"Baseline among all data: {statistics.mean(results)} \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-17T10:32:44.864511Z","iopub.execute_input":"2025-07-17T10:32:44.864728Z","iopub.status.idle":"2025-07-17T10:32:44.870153Z","shell.execute_reply.started":"2025-07-17T10:32:44.864703Z","shell.execute_reply":"2025-07-17T10:32:44.869217Z"}},"outputs":[{"name":"stdout","text":"Baseline among all data: 0.022245158045881203 \n","output_type":"stream"}],"execution_count":38}]}